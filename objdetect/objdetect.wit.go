// Code generated by wit-bindgen-go. DO NOT EDIT.

// Package objdetect represents the imported interface "wasm:cv/objdetect".
package objdetect

import (
	"go.bytecodealliance.org/cm"
	"wasmcv.org/wasm/cv/mat"
	"wasmcv.org/wasm/cv/types"
)

// Mat represents the imported type alias "wasm:cv/objdetect#mat".
//
// See [mat.Mat] for more information.
type Mat = mat.Mat

// ErrorResult represents the type alias "wasm:cv/objdetect#error-result".
//
// See [types.ErrorResult] for more information.
type ErrorResult = types.ErrorResult

// Size represents the type alias "wasm:cv/objdetect#size".
//
// See [types.Size] for more information.
type Size = types.Size

// Rect represents the type alias "wasm:cv/objdetect#rect".
//
// See [types.Rect] for more information.
type Rect = types.Rect

// CascadeClassifier represents the imported resource "wasm:cv/objdetect#cascade-classifier".
//
// CascadeClassifier is a cascade classifier class for object detection.
//
//	resource cascade-classifier
type CascadeClassifier cm.Resource

// ResourceDrop represents the imported resource-drop for resource "cascade-classifier".
//
// Drops a resource handle.
//
//go:nosplit
func (self CascadeClassifier) ResourceDrop() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_CascadeClassifierResourceDrop((uint32)(self0))
	return
}

// NewCascadeClassifier represents the imported constructor for resource "cascade-classifier".
//
// NewCascadeClassifier returns a new CascadeClassifier.
//
// For further details, please see:
// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#a5f7fb43c60c95ca5ebab78483de02516
//
//	constructor(name: string)
//
//go:nosplit
func NewCascadeClassifier(name string) (result CascadeClassifier) {
	name0, name1 := cm.LowerString(name)
	result0 := wasmimport_NewCascadeClassifier((*uint8)(name0), (uint32)(name1))
	result = cm.Reinterpret[CascadeClassifier]((uint32)(result0))
	return
}

// Close represents the imported method "close".
//
// Close the CascadeClassifier
//
//	close: func()
//
//go:nosplit
func (self CascadeClassifier) Close() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_CascadeClassifierClose((uint32)(self0))
	return
}

// DetectMultiScale represents the imported method "detect-multi-scale".
//
// DetectMultiScale detects objects of different sizes in the input Mat image.
// The detected objects are returned as a slice of image.Rectangle structs.
//
// For further details, please see:
// http://docs.opencv.org/master/d1/de5/classcv_1_1CascadeClassifier.html#aaf8181cb63968136476ec4204ffca498
//
//	detect-multi-scale: func(image: mat) -> result<list<rect>, error-result>
//
//go:nosplit
func (self CascadeClassifier) DetectMultiScale(image Mat) (result cm.Result[cm.List[Rect], cm.List[Rect], ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	image0 := cm.Reinterpret[uint32](image)
	wasmimport_CascadeClassifierDetectMultiScale((uint32)(self0), (uint32)(image0), &result)
	return
}

// DetectMultiScaleWithParams represents the imported method "detect-multi-scale-with-params".
//
// DetectMultiScaleWithParams detects objects of different sizes in the input Mat
// image.
// The detected objects are returned as a slice of image.Rectangle structs.
//
// For further details, please see:
// http://docs.opencv.org/master/d1/de5/classcv_1_1CascadeClassifier.html#aaf8181cb63968136476ec4204ffca498
//
//	detect-multi-scale-with-params: func(image: mat, scale: f64, min-neighbors: u32,
//	%flags: u32, min-size: size, max-size: size) -> result<list<rect>, error-result>
//
//go:nosplit
func (self CascadeClassifier) DetectMultiScaleWithParams(image Mat, scale float64, minNeighbors uint32, flags uint32, minSize Size, maxSize Size) (result cm.Result[cm.List[Rect], cm.List[Rect], ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	image0 := cm.Reinterpret[uint32](image)
	scale0 := (float64)(scale)
	minNeighbors0 := (uint32)(minNeighbors)
	flags0 := (uint32)(flags)
	minSize0, minSize1 := lower_Size(minSize)
	maxSize0, maxSize1 := lower_Size(maxSize)
	wasmimport_CascadeClassifierDetectMultiScaleWithParams((uint32)(self0), (uint32)(image0), (float64)(scale0), (uint32)(minNeighbors0), (uint32)(flags0), (uint32)(minSize0), (uint32)(minSize1), (uint32)(maxSize0), (uint32)(maxSize1), &result)
	return
}

// Load represents the imported method "load".
//
// Load cascade classifier from a file.
//
// For further details, please see:
// http://docs.opencv.org/master/d1/de5/classcv_1_1CascadeClassifier.html#a1a5884c8cc749422f9eb77c2471958bc
//
//	load: func(file: string) -> bool
//
//go:nosplit
func (self CascadeClassifier) Load(file string) (result bool) {
	self0 := cm.Reinterpret[uint32](self)
	file0, file1 := cm.LowerString(file)
	result0 := wasmimport_CascadeClassifierLoad((uint32)(self0), (*uint8)(file0), (uint32)(file1))
	result = (bool)(cm.U32ToBool((uint32)(result0)))
	return
}

// HOGDescriptor represents the imported resource "wasm:cv/objdetect#HOG-descriptor".
//
// HOGDescriptor is a Histogram Of Gradiants (HOG) for object detection.
//
// For further details, please see:
// https://docs.opencv.org/master/d5/d33/structcv_1_1HOGDescriptor.html#a723b95b709cfd3f95cf9e616de988fc8
//
//	resource HOG-descriptor
type HOGDescriptor cm.Resource

// ResourceDrop represents the imported resource-drop for resource "HOG-descriptor".
//
// Drops a resource handle.
//
//go:nosplit
func (self HOGDescriptor) ResourceDrop() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_HOGDescriptorResourceDrop((uint32)(self0))
	return
}

// NewHOGDescriptor represents the imported constructor for resource "HOG-descriptor".
//
// NewHOGDescriptor returns a new HOGDescriptor.
//
//	constructor(name: string)
//
//go:nosplit
func NewHOGDescriptor(name string) (result HOGDescriptor) {
	name0, name1 := cm.LowerString(name)
	result0 := wasmimport_NewHOGDescriptor((*uint8)(name0), (uint32)(name1))
	result = cm.Reinterpret[HOGDescriptor]((uint32)(result0))
	return
}

// Close represents the imported method "close".
//
// Close the HOGDescriptor
//
//	close: func()
//
//go:nosplit
func (self HOGDescriptor) Close() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_HOGDescriptorClose((uint32)(self0))
	return
}

// DetectMultiScale represents the imported method "detect-multi-scale".
//
// DetectMultiScale detects objects of different sizes in the input Mat image.
// The detected objects are returned as a slice of image.Rectangle structs.
//
// For further details, please see:
// https://docs.opencv.org/master/d5/d33/structcv_1_1HOGDescriptor.html#a660e5cd036fd5ddf0f5767b352acd948
//
//	detect-multi-scale: func(image: mat) -> result<list<rect>, error-result>
//
//go:nosplit
func (self HOGDescriptor) DetectMultiScale(image Mat) (result cm.Result[cm.List[Rect], cm.List[Rect], ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	image0 := cm.Reinterpret[uint32](image)
	wasmimport_HOGDescriptorDetectMultiScale((uint32)(self0), (uint32)(image0), &result)
	return
}

// DetectMultiScaleWithParams represents the imported method "detect-multi-scale-with-params".
//
// DetectMultiScaleWithParams detects objects of different sizes in the input Mat
// image.
// The detected objects are returned as a slice of image.Rectangle structs.
//
// For further details, please see:
// https://docs.opencv.org/master/d5/d33/structcv_1_1HOGDescriptor.html#a660e5cd036fd5ddf0f5767b352acd948
//
//	detect-multi-scale-with-params: func(image: mat, hit-threshold: f64, win-stride:
//	size, padding: size, scale: f64, final-threshold: f64, use-meanshift-grouping:
//	bool) -> result<list<rect>, error-result>
//
//go:nosplit
func (self HOGDescriptor) DetectMultiScaleWithParams(image Mat, hitThreshold float64, winStride Size, padding Size, scale float64, finalThreshold float64, useMeanshiftGrouping bool) (result cm.Result[cm.List[Rect], cm.List[Rect], ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	image0 := cm.Reinterpret[uint32](image)
	hitThreshold0 := (float64)(hitThreshold)
	winStride0, winStride1 := lower_Size(winStride)
	padding0, padding1 := lower_Size(padding)
	scale0 := (float64)(scale)
	finalThreshold0 := (float64)(finalThreshold)
	useMeanshiftGrouping0 := (uint32)(cm.BoolToU32(useMeanshiftGrouping))
	wasmimport_HOGDescriptorDetectMultiScaleWithParams((uint32)(self0), (uint32)(image0), (float64)(hitThreshold0), (uint32)(winStride0), (uint32)(winStride1), (uint32)(padding0), (uint32)(padding1), (float64)(scale0), (float64)(finalThreshold0), (uint32)(useMeanshiftGrouping0), &result)
	return
}

// FaceDetectorYN represents the imported resource "wasm:cv/objdetect#face-detector-YN".
//
//	resource face-detector-YN
type FaceDetectorYN cm.Resource

// ResourceDrop represents the imported resource-drop for resource "face-detector-YN".
//
// Drops a resource handle.
//
//go:nosplit
func (self FaceDetectorYN) ResourceDrop() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_FaceDetectorYNResourceDrop((uint32)(self0))
	return
}

// NewFaceDetectorYN represents the imported constructor for resource "face-detector-YN".
//
// Creates an instance of face detector YN with given parameters.
//
// For further details, please see:
// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#a5f7fb43c60c95ca5ebab78483de02516
//
//	constructor(model: string, config: string, input-size: size)
//
//go:nosplit
func NewFaceDetectorYN(model string, config string, inputSize Size) (result FaceDetectorYN) {
	model0, model1 := cm.LowerString(model)
	config0, config1 := cm.LowerString(config)
	inputSize0, inputSize1 := lower_Size(inputSize)
	result0 := wasmimport_NewFaceDetectorYN((*uint8)(model0), (uint32)(model1), (*uint8)(config0), (uint32)(config1), (uint32)(inputSize0), (uint32)(inputSize1))
	result = cm.Reinterpret[FaceDetectorYN]((uint32)(result0))
	return
}

// FaceDetectorYNNewWithParams represents the imported static function "new-with-params".
//
// Creates an instance of face detector YN with given parameters.
//
// For further details, please see:
// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#a5f7fb43c60c95ca5ebab78483de02516
//
//	new-with-params: static func(model: string, config: string, input-size: size, score-threshold:
//	f32, nms-threshold: f32, top-k: u32, backend-id: u32, target-id: u32) -> face-detector-YN
//
//go:nosplit
func FaceDetectorYNNewWithParams(model string, config string, inputSize Size, scoreThreshold float32, nmsThreshold float32, topK uint32, backendID uint32, targetID uint32) (result FaceDetectorYN) {
	model0, model1 := cm.LowerString(model)
	config0, config1 := cm.LowerString(config)
	inputSize0, inputSize1 := lower_Size(inputSize)
	scoreThreshold0 := (float32)(scoreThreshold)
	nmsThreshold0 := (float32)(nmsThreshold)
	topK0 := (uint32)(topK)
	backendId0 := (uint32)(backendID)
	targetId0 := (uint32)(targetID)
	result0 := wasmimport_FaceDetectorYNNewWithParams((*uint8)(model0), (uint32)(model1), (*uint8)(config0), (uint32)(config1), (uint32)(inputSize0), (uint32)(inputSize1), (float32)(scoreThreshold0), (float32)(nmsThreshold0), (uint32)(topK0), (uint32)(backendId0), (uint32)(targetId0))
	result = cm.Reinterpret[FaceDetectorYN]((uint32)(result0))
	return
}

// Close represents the imported method "close".
//
// Close the face detector
//
//	close: func()
//
//go:nosplit
func (self FaceDetectorYN) Close() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_FaceDetectorYNClose((uint32)(self0))
	return
}

// Detect represents the imported method "detect".
//
// Detects faces in the input image.
//
// For further details, please see:
// https://docs.opencv.org/4.x/df/d20/classcv_1_1FaceDetectorYN.html#ac05bd075ca3e6edc0e328927aae6f45b
//
//	detect: func(input: mat) -> result<mat, error-result>
//
//go:nosplit
func (self FaceDetectorYN) Detect(input Mat) (result cm.Result[string, Mat, ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	input0 := cm.Reinterpret[uint32](input)
	wasmimport_FaceDetectorYNDetect((uint32)(self0), (uint32)(input0), &result)
	return
}

// GetInputSize represents the imported method "get-input-size".
//
//	get-input-size: func() -> size
//
//go:nosplit
func (self FaceDetectorYN) GetInputSize() (result Size) {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_FaceDetectorYNGetInputSize((uint32)(self0), &result)
	return
}

// GetNmsThreshold represents the imported method "get-nms-threshold".
//
//	get-nms-threshold: func() -> f32
//
//go:nosplit
func (self FaceDetectorYN) GetNmsThreshold() (result float32) {
	self0 := cm.Reinterpret[uint32](self)
	result0 := wasmimport_FaceDetectorYNGetNmsThreshold((uint32)(self0))
	result = (float32)((float32)(result0))
	return
}

// GetScoreThreshold represents the imported method "get-score-threshold".
//
//	get-score-threshold: func() -> f32
//
//go:nosplit
func (self FaceDetectorYN) GetScoreThreshold() (result float32) {
	self0 := cm.Reinterpret[uint32](self)
	result0 := wasmimport_FaceDetectorYNGetScoreThreshold((uint32)(self0))
	result = (float32)((float32)(result0))
	return
}

// GetTopk represents the imported method "get-topk".
//
//	get-topk: func() -> u32
//
//go:nosplit
func (self FaceDetectorYN) GetTopk() (result uint32) {
	self0 := cm.Reinterpret[uint32](self)
	result0 := wasmimport_FaceDetectorYNGetTopk((uint32)(self0))
	result = (uint32)((uint32)(result0))
	return
}

// SetInputSize represents the imported method "set-input-size".
//
//	set-input-size: func(size: size)
//
//go:nosplit
func (self FaceDetectorYN) SetInputSize(size Size) {
	self0 := cm.Reinterpret[uint32](self)
	size0, size1 := lower_Size(size)
	wasmimport_FaceDetectorYNSetInputSize((uint32)(self0), (uint32)(size0), (uint32)(size1))
	return
}

// SetNmsThreshold represents the imported method "set-nms-threshold".
//
//	set-nms-threshold: func(threshold: f32)
//
//go:nosplit
func (self FaceDetectorYN) SetNmsThreshold(threshold float32) {
	self0 := cm.Reinterpret[uint32](self)
	threshold0 := (float32)(threshold)
	wasmimport_FaceDetectorYNSetNmsThreshold((uint32)(self0), (float32)(threshold0))
	return
}

// SetScoreThreshold represents the imported method "set-score-threshold".
//
//	set-score-threshold: func(threshold: f32)
//
//go:nosplit
func (self FaceDetectorYN) SetScoreThreshold(threshold float32) {
	self0 := cm.Reinterpret[uint32](self)
	threshold0 := (float32)(threshold)
	wasmimport_FaceDetectorYNSetScoreThreshold((uint32)(self0), (float32)(threshold0))
	return
}

// SetTopk represents the imported method "set-topk".
//
//	set-topk: func(topk: u32)
//
//go:nosplit
func (self FaceDetectorYN) SetTopk(topk uint32) {
	self0 := cm.Reinterpret[uint32](self)
	topk0 := (uint32)(topk)
	wasmimport_FaceDetectorYNSetTopk((uint32)(self0), (uint32)(topk0))
	return
}

// FaceDistanceType represents the enum "wasm:cv/objdetect#face-distance-type".
//
//	enum face-distance-type {
//		face-distance-type-cosine,
//		face-distance-norm-l2
//	}
type FaceDistanceType uint8

const (
	FaceDistanceTypeFaceDistanceTypeCosine FaceDistanceType = iota
	FaceDistanceTypeFaceDistanceNormL2
)

var _FaceDistanceTypeStrings = [2]string{
	"face-distance-type-cosine",
	"face-distance-norm-l2",
}

// String implements [fmt.Stringer], returning the enum case name of e.
func (e FaceDistanceType) String() string {
	return _FaceDistanceTypeStrings[e]
}

// MarshalText implements [encoding.TextMarshaler].
func (e FaceDistanceType) MarshalText() ([]byte, error) {
	return []byte(e.String()), nil
}

// UnmarshalText implements [encoding.TextUnmarshaler], unmarshaling into an enum
// case. Returns an error if the supplied text is not one of the enum cases.
func (e *FaceDistanceType) UnmarshalText(text []byte) error {
	return _FaceDistanceTypeUnmarshalCase(e, text)
}

var _FaceDistanceTypeUnmarshalCase = cm.CaseUnmarshaler[FaceDistanceType](_FaceDistanceTypeStrings[:])

// FaceRecognizerSF represents the imported resource "wasm:cv/objdetect#face-recognizer-SF".
//
//	resource face-recognizer-SF
type FaceRecognizerSF cm.Resource

// ResourceDrop represents the imported resource-drop for resource "face-recognizer-SF".
//
// Drops a resource handle.
//
//go:nosplit
func (self FaceRecognizerSF) ResourceDrop() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_FaceRecognizerSFResourceDrop((uint32)(self0))
	return
}

// NewFaceRecognizerSF represents the imported constructor for resource "face-recognizer-SF".
//
// Creates an instance of FaceRecognizerSF with given parameters.
//
// For further details, please see:
// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a04df90b0cd7d26d350acd92621a35743
//
//	constructor(model: string, config: string)
//
//go:nosplit
func NewFaceRecognizerSF(model string, config string) (result FaceRecognizerSF) {
	model0, model1 := cm.LowerString(model)
	config0, config1 := cm.LowerString(config)
	result0 := wasmimport_NewFaceRecognizerSF((*uint8)(model0), (uint32)(model1), (*uint8)(config0), (uint32)(config1))
	result = cm.Reinterpret[FaceRecognizerSF]((uint32)(result0))
	return
}

// FaceRecognizerSFNewWithParams represents the imported static function "new-with-params".
//
// Creates an instance of FaceRecognizerSF with given parameters.
//
// For further details, please see:
// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a04df90b0cd7d26d350acd92621a35743
//
//	new-with-params: static func(model: string, config: string, backend-id: u32, target-id:
//	u32) -> face-recognizer-SF
//
//go:nosplit
func FaceRecognizerSFNewWithParams(model string, config string, backendID uint32, targetID uint32) (result FaceRecognizerSF) {
	model0, model1 := cm.LowerString(model)
	config0, config1 := cm.LowerString(config)
	backendId0 := (uint32)(backendID)
	targetId0 := (uint32)(targetID)
	result0 := wasmimport_FaceRecognizerSFNewWithParams((*uint8)(model0), (uint32)(model1), (*uint8)(config0), (uint32)(config1), (uint32)(backendId0), (uint32)(targetId0))
	result = cm.Reinterpret[FaceRecognizerSF]((uint32)(result0))
	return
}

// AlignCrop represents the imported method "align-crop".
//
// Aligns detected face with the source input image and crops it.
//
// For further details, please see:
// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a84492908abecbc9362b4ddc8d46b8345
//
//	align-crop: func(src: mat, face-box: mat) -> result<mat, error-result>
//
//go:nosplit
func (self FaceRecognizerSF) AlignCrop(src Mat, faceBox Mat) (result cm.Result[string, Mat, ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	src0 := cm.Reinterpret[uint32](src)
	faceBox0 := cm.Reinterpret[uint32](faceBox)
	wasmimport_FaceRecognizerSFAlignCrop((uint32)(self0), (uint32)(src0), (uint32)(faceBox0), &result)
	return
}

// Close represents the imported method "close".
//
// Close the face FaceRecognizerSF
//
//	close: func()
//
//go:nosplit
func (self FaceRecognizerSF) Close() {
	self0 := cm.Reinterpret[uint32](self)
	wasmimport_FaceRecognizerSFClose((uint32)(self0))
	return
}

// Feature represents the imported method "feature".
//
// Feature extracts face feature from aligned image.
//
// For further details, please see:
// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#ab1b4a3c12213e89091a490c573dc5aba
//
//	feature: func(aligned: mat) -> result<mat, error-result>
//
//go:nosplit
func (self FaceRecognizerSF) Feature(aligned Mat) (result cm.Result[string, Mat, ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	aligned0 := cm.Reinterpret[uint32](aligned)
	wasmimport_FaceRecognizerSFFeature((uint32)(self0), (uint32)(aligned0), &result)
	return
}

// Match represents the imported method "match".
//
// Match calculates the distance between two face features.
//
// For further details, please see:
// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a2f0362ca1e64320a1f3ba7e1386d0219
//
//	match: func(face1: mat, face2: mat) -> result<f32, error-result>
//
//go:nosplit
func (self FaceRecognizerSF) Match(face1 Mat, face2 Mat) (result cm.Result[string, float32, ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	face10 := cm.Reinterpret[uint32](face1)
	face20 := cm.Reinterpret[uint32](face2)
	wasmimport_FaceRecognizerSFMatch((uint32)(self0), (uint32)(face10), (uint32)(face20), &result)
	return
}

// MatchWithParams represents the imported method "match-with-params".
//
// Match calculates the distance between two face features.
//
// For further details, please see:
// https://docs.opencv.org/4.x/da/d09/classcv_1_1FaceRecognizerSF.html#a2f0362ca1e64320a1f3ba7e1386d0219
//
//	match-with-params: func(face1: mat, face2: mat, distance: face-distance-type) ->
//	result<f32, error-result>
//
//go:nosplit
func (self FaceRecognizerSF) MatchWithParams(face1 Mat, face2 Mat, distance FaceDistanceType) (result cm.Result[string, float32, ErrorResult]) {
	self0 := cm.Reinterpret[uint32](self)
	face10 := cm.Reinterpret[uint32](face1)
	face20 := cm.Reinterpret[uint32](face2)
	distance0 := (uint32)(distance)
	wasmimport_FaceRecognizerSFMatchWithParams((uint32)(self0), (uint32)(face10), (uint32)(face20), (uint32)(distance0), &result)
	return
}
